{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de80a558-126b-4e18-842e-e925e769b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASEDIR = Path(\"/workspaces/HARP/\") / \"src\"  # Replace with your own basedir path for the repo\n",
    "\n",
    "sys.path.insert(0, str(BASEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1974c3-afec-46c5-93e8-7b48c7fb1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import re\n",
    "import textwrap\n",
    "import time\n",
    "import traceback\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, clear_output, display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b378ce4e-35f2-4f9d-aeae-52bbd93cb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.eval import create_batch\n",
    "from eval.prompts import *\n",
    "from eval.utils import read_jsonl, write_jsonl, get_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90ed19-2423-4dec-b46d-fe92e1ca7321",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818f86de-7457-4a9e-ad7f-0c644db0cd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4780"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = read_jsonl(BASEDIR / \"data/processed/HARP.jsonl\")\n",
    "dataset_map = {get_uid(p): p for p in dataset}\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d0c13-abd9-4bac-9074-0627157bf1ef",
   "metadata": {},
   "source": [
    "# Run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b9ce517-3d57-4cb1-8540-d71691645522",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03134e5-b932-42fd-a3d5-eb9b7ddac568",
   "metadata": {},
   "source": [
    "## Create batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83311326-d5f7-4928-b98e-865626d06178",
   "metadata": {},
   "source": [
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763d67c7-4bcc-4fe8-831a-154ae6de62c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a helpful assistant.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "516329f0-f7ec-4b93-8bf2-5be1adbb4587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Solve the following math problem. The last line of your response should be of the form \"Answer:\\n$ANSWER\" (without quotes) where $ANSWER is the answer to the problem. Remember to put your answer on its own line after \"Answer:\", and you do not need to use a \\\\boxed command.\\n\\n    {problem}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_openai_o1_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "316968f8-53b6-4a8e-bdb7-5d15e4e157ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = create_batch(\n",
    "    dataset,\n",
    "    api=\"openai\",\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    fewshot_messages=[],\n",
    "    system_prompt=gpt4_system_instruction,\n",
    "    user_prompt_template=modified_openai_o1_prompt_template,\n",
    "    ending_assistant_prompt=None,\n",
    "    max_tokens=2048,\n",
    "    temperature=0,\n",
    "    seed=0,\n",
    "    logprobs=True,\n",
    "    top_logprobs=None,\n",
    "    # just to remove irrelevant params\n",
    "    top_p=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c5c4b8-dd5e-45cf-83d1-e5ebff03bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(batch, BASEDIR / \"inputs/short_answer/gpt-4o-mini-2024-07-18/batch.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea7c8832-964e-4a95-af38-90c197ee6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASEDIR / \"inputs/short_answer/gpt-4o-mini-2024-07-18/batch.jsonl\", \"rb\") as f:\n",
    "    batch_input_file = client.files.create(file=f, purpose=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "219298a5-6c8a-436d-a188-9e7ea9087d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-JPFPVMLebKTzoFhTzCkpEZKn'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3406167-1868-44be-9066-91681928e5ba",
   "metadata": {},
   "source": [
    "## Run batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3523aa67-70f1-46dc-b9c5-b90929b8b942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_672d48e31fcc8190bd8d281c756d2c67', completion_window='24h', created_at=1731021027, endpoint='/v1/chat/completions', input_file_id='file-JPFPVMLebKTzoFhTzCkpEZKn', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1731107427, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'gpt-4o-mini-2024-07-18 eval no-top-logprobs'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.create(\n",
    "    input_file_id=batch_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"gpt-4o-mini-2024-07-18 eval no-top-logprobs\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100aa3f7-c532-4fd9-ad99-a877352494f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_NAME = \"batch_672d48e31fcc8190bd8d281c756d2c67\"  # Replace with your own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6349cb-9237-4f6a-812a-7c8ebe01067c",
   "metadata": {},
   "source": [
    "## Check on status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37463b54-3370-4b84-b326-ad7192edaa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_672d48e31fcc8190bd8d281c756d2c67', completion_window='24h', created_at=1731021027, endpoint='/v1/chat/completions', input_file_id='file-JPFPVMLebKTzoFhTzCkpEZKn', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1731107427, failed_at=None, finalizing_at=None, in_progress_at=1731021028, metadata={'description': 'gpt-4o-mini-2024-07-18 eval no-top-logprobs'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=4794))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(BATCH_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbca6f3-8c9f-47aa-bb35-eea844241bf4",
   "metadata": {},
   "source": [
    "## Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c587a1fa-d9c7-4f6c-b4a4-0a786d848d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = client.batches.retrieve(BATCH_NAME).output_file_id\n",
    "results = client.files.content(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9524b0d9-f719-4e62-8246-f0b145fd8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.write_to_file(BASEDIR / \"outputs/short_answer/gpt-4o-mini-2024-07-18/outputs.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
