{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c10cbe-659f-444c-a855-c6bae55a1df3",
   "metadata": {},
   "source": [
    "# Gemini 1.5 Pro Multiple Choice Shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d101b202-b0cb-4afd-8aa3-6859de242e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASEDIR = Path(\"/workspaces/HARP/\") / \"src\"  # Replace with your own basedir path for the repo\n",
    "\n",
    "sys.path.insert(0, str(BASEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d796a1-30da-49ab-9cb1-02ca6206d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import re\n",
    "import textwrap\n",
    "import time\n",
    "import traceback\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from IPython.display import Markdown, clear_output, display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import vertexai\n",
    "from vertexai.batch_prediction._batch_prediction import BatchPredictionJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6961601f-2e3f-4cc4-9ab6-343749d0999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.api import safe_unified_api_call\n",
    "from eval.costs import count_tokens, get_pricing\n",
    "from eval.eval import run_one, create_batch, make_answer_check_dict_from_jsonl\n",
    "from eval.parsing_lib import *\n",
    "from eval.latex_answer_check import *\n",
    "from eval.prompt import create_prompt\n",
    "from eval.prompts import *\n",
    "from eval.utils import AMC_LETTER_CHOICES, read_jsonl, write_jsonl, get_uid, upload_blob, download_blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530a065-3ffc-4973-964d-1a26a7dbcfeb",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8172ba18-dd54-4fe2-8bfc-9e191468f1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4115"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't use HARP_mcq.jsonl here because we used the original ordering of answer choices\n",
    "dataset = [x for x in read_jsonl(BASEDIR / \"data/processed/HARP_raw.jsonl\") if x[\"choices\"] is not None]# and x[\"subject\"] != \"calculus\"]\n",
    "dataset_map = {get_uid(p): p for p in dataset}\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea919c42-ecfd-443e-8643-1a6560c5d875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([p[\"answer_choice\"] is not None for p in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57caa81f-8df0-4726-a96c-b0947e85edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1612, 3: 1136, 1: 858, 4: 504})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([p[\"level\"] for p in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff58a2c-b30d-49c4-8ca0-94624003ff7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'D': 991, 'C': 934, 'B': 929, 'E': 641, 'A': 615})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([p[\"answer_choice\"] for p in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9555787c-1014-480d-a268-256a1ac176b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.2272506082725061,\n",
       " 'D': 0.2411192214111922,\n",
       " 'E': 0.1559610705596107,\n",
       " 'A': 0.14963503649635038,\n",
       " 'B': 0.22603406326034065}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{c: x / len(dataset) for c, x in Counter([p[\"answer_choice\"] for p in dataset]).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a794f9-f9bc-492f-a017-37e06ca6335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2075872153255072"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((x / len(dataset))**2 for c, x in Counter([p[\"answer_choice\"] for p in dataset]).items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532bd49a-7e93-4fc8-b508-3edae5528815",
   "metadata": {},
   "source": [
    "# Run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a4a7847-7bd4-41d5-b73b-c3ec92f14d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=os.environ.get(\"VERTEXAI_PROJECT_ID\"), location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b78a16-daec-4a9d-9e7d-49167f8d3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = os.environ.get(\"GCLOUD_BUCKET_NAME\")  # Should have the form \"cloud-ai-platform-<YOUR_BUCKET>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28ac58-4efa-43ed-a7a9-2a3d317e5537",
   "metadata": {},
   "source": [
    "## Shuffle choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d623b0e1-92dd-4658-ada4-349388baeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derangement(length=5):\n",
    "    letters = AMC_LETTER_CHOICES[:length]\n",
    "    while True:\n",
    "        shuffle = np.random.permutation(letters)\n",
    "        is_derangement = True\n",
    "        for l, x in zip(letters, shuffle):\n",
    "            if l == x:\n",
    "                is_derangement = False\n",
    "        if is_derangement:\n",
    "            return [str(x) for x in shuffle] + AMC_LETTER_CHOICES[length:]\n",
    "\n",
    "def get_distinct_derangements(n, length=5):\n",
    "    # Note that there's 44 unique derangements\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        while True:\n",
    "            d = get_derangement(length)\n",
    "            if d not in res:\n",
    "                res.append(d)\n",
    "                break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168e8297-066e-42df-ae2e-92f08acba487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_problem_with_shuffled_choices(prob, new_order):\n",
    "    new_prob = prob.copy()\n",
    "    \n",
    "    new_choices = {}\n",
    "    for letter, new_letter in zip(AMC_LETTER_CHOICES, new_order):\n",
    "        new_choices[new_letter] = new_prob[\"choices\"][letter]\n",
    "    new_choices = {l: new_choices[l] for l in AMC_LETTER_CHOICES}\n",
    "    new_prob[\"choices\"] = new_choices\n",
    "    new_prob[\"answer_choice\"] = new_order[AMC_LETTER_CHOICES.index(new_prob[\"answer_choice\"])]\n",
    "    return new_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "123edfd8-2c48-44f9-9b87-1170b5310181",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_derangements = {}\n",
    "for i, prob in enumerate(dataset):\n",
    "    choices = prob[\"choices\"]\n",
    "    length = 5\n",
    "    if \"none of\" in choices[\"E\"].lower() or \"all of\" in choices[\"E\"].lower():\n",
    "        length = 4\n",
    "\n",
    "    seen_ds = first_derangements[i].copy()\n",
    "    for i in range(3):\n",
    "        d = get_derangement(length)\n",
    "        while d in seen_ds:\n",
    "            d = get_derangement(length)\n",
    "        seen_ds.append(d)\n",
    "    all_derangements[get_uid(prob)] = seen_ds\n",
    "\n",
    "with open(BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/mcq_derangements.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(all_derangements, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "919f5986-047f-49ea-bdf1-96b175613d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/mcq_derangements.pkl\", \"rb\") as f:\n",
    "    all_derangements = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8df1fff-6376-4efc-9068-eb99d26ccec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_RUNS = 5\n",
    "\n",
    "datasets = [[] for _ in range(TOTAL_RUNS)]\n",
    "for prob in dataset:\n",
    "    derangements = all_derangements[get_uid(prob)]\n",
    "    choices = prob[\"choices\"]\n",
    "    length = 5\n",
    "    if \"none of\" in choices[\"E\"].lower() or \"all of\" in choices[\"E\"].lower():\n",
    "        length = 4\n",
    "\n",
    "    for t in range(TOTAL_RUNS):\n",
    "        datasets[t].append(\n",
    "            create_problem_with_shuffled_choices(prob, derangements[t])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df8450bb-67ae-4ec1-b1cc-76ff65eb172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_map = [{get_uid(p): p for p in datasets[t]} for t in range(TOTAL_RUNS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3301067b-f32a-46b2-ba72-f13d09a93a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'E': 850, 'A': 848, 'D': 818, 'C': 798, 'B': 796})\n",
      "Counter({'A': 932, 'E': 857, 'C': 777, 'B': 773, 'D': 771})\n",
      "Counter({'E': 854, 'A': 853, 'B': 810, 'C': 798, 'D': 795})\n",
      "Counter({'A': 888, 'E': 855, 'B': 794, 'C': 792, 'D': 781})\n",
      "Counter({'A': 903, 'E': 871, 'C': 802, 'B': 798, 'D': 736})\n"
     ]
    }
   ],
   "source": [
    "for t in range(TOTAL_RUNS):\n",
    "    print(Counter(p[\"answer_choice\"] for p in datasets[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777ca51-9e54-4b33-8d2e-32304459f229",
   "metadata": {},
   "source": [
    "## Create batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4ca2f-82d7-4012-9188-313ec3e03228",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(TOTAL_RUNS):\n",
    "    batch = create_batch(\n",
    "        datasets[t],\n",
    "        api=\"google\",\n",
    "        model=\"gemini-1.5-pro-002\",\n",
    "        fewshot_messages=[],\n",
    "        system_prompt=gemini_multiple_choice_0shot_sysprompt,\n",
    "        prompt_choices=\"newline_paren\",\n",
    "        max_tokens=2048,\n",
    "        temperature=0,\n",
    "        seed=0,\n",
    "        stop_sequences=[\"I hope it is correct.\"],\n",
    "        # just to remove irrelevant params\n",
    "        logprobs=None,\n",
    "        top_p=None,\n",
    "    )\n",
    "    write_jsonl(\n",
    "        batch,\n",
    "        BASEDIR / f\"inputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle{t+1}.jsonl\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d29b20-3d43-4c76-af1e-66d60e975b8e",
   "metadata": {},
   "source": [
    "## Upload to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146d869-e104-41f6-ace9-1f4f5884ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(TOTAL_RUNS):\n",
    "    upload_blob(\n",
    "        BUCKET_NAME,\n",
    "        BASEDIR / f\"inputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle{t+1}.jsonl\",\n",
    "        f\"prompt_data/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle{t+1}.jsonl\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ac3e5-3ff5-431f-9134-802e3904a034",
   "metadata": {},
   "source": [
    "## Run batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d9282-4a2a-4cb1-860d-a5d599b945ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(TOTAL_RUNS):\n",
    "    BatchPredictionJob.submit(\n",
    "        source_model=\"gemini-1.5-pro-002\",\n",
    "        input_dataset=f\"gs://{BUCKET_NAME}/prompt_data/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle{t+1}.jsonl\",\n",
    "        output_uri_prefix=f\"gs://{BUCKET_NAME}/outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle{t+1}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c26ec-123d-4d60-82af-ef78893687fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle1/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_newline-paren_shuffle1.jsonl\",\n",
    ")\n",
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle2/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_newline-paren_shuffle2.jsonl\",\n",
    ")\n",
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle3/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_newline-paren_shuffle3.jsonl\",\n",
    ")\n",
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle4/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_newline-paren_shuffle4.jsonl\",\n",
    ")\n",
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren_shuffle5/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_newline-paren_shuffle5.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e07448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
