{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c10cbe-659f-444c-a855-c6bae55a1df3",
   "metadata": {},
   "source": [
    "# Gemini 1.5 Pro Multiple Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be048383-6212-42ff-8826-23dbd3bafafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASEDIR = Path(\"/workspaces/HARP/\") / \"src\"  # Replace with your own basedir path for the repo\n",
    "\n",
    "sys.path.insert(0, str(BASEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ed9091-1e26-4a1b-ab97-11f92846b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import re\n",
    "import textwrap\n",
    "import time\n",
    "import traceback\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from IPython.display import Markdown, clear_output, display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import vertexai\n",
    "from vertexai.batch_prediction._batch_prediction import BatchPredictionJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8580f062-cd20-4c6a-811b-5633d687c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.api import safe_unified_api_call\n",
    "from eval.costs import count_tokens, get_pricing\n",
    "from eval.eval import run_one, create_batch, make_answer_check_dict_from_jsonl\n",
    "from eval.parsing_lib import *\n",
    "from eval.latex_answer_check import *\n",
    "from eval.prompt import create_prompt\n",
    "from eval.prompts import *\n",
    "from eval.utils import read_jsonl, write_jsonl, get_uid, upload_blob, download_blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f2acc-65cd-4b65-9eee-4746f592839f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a073cf1-5535-463e-a9d0-ce1a8a084657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4110"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't use HARP_mcq.jsonl here because we used the original ordering of answer choices\n",
    "dataset = [x for x in read_jsonl(BASEDIR / \"data/processed/HARP_raw.jsonl\") if x[\"choices\"] is not None and x[\"subject\"] != \"calculus\"]\n",
    "dataset_map = {get_uid(p): p for p in dataset}\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb959a66-cdbe-4501-b7df-7f736699a044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([p[\"answer_choice\"] is not None for p in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c0f152-d930-46cf-9895-4051fd75b7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1612, 3: 1136, 1: 858, 4: 504})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([p[\"level\"] for p in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa6ae40-07e2-4f94-b4b7-b9e4b952de36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'E': 903, 'A': 862, 'C': 833, 'B': 758, 'D': 754})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([p[\"answer_choice\"] for p in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58fa0708-2f69-4f7f-a56c-c551e7a8dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 0.1834549878345499,\n",
       " 'C': 0.202676399026764,\n",
       " 'E': 0.2197080291970803,\n",
       " 'B': 0.18442822384428223,\n",
       " 'A': 0.2097323600973236}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{c: x / len(dataset) for c, x in Counter([p[\"answer_choice\"] for p in dataset]).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a47abd0-8cd5-499f-88b4-8e5c053daec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2010065059998461"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((x / len(dataset))**2 for c, x in Counter([p[\"answer_choice\"] for p in dataset]).items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532bd49a-7e93-4fc8-b508-3edae5528815",
   "metadata": {},
   "source": [
    "# Run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a4a7847-7bd4-41d5-b73b-c3ec92f14d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=os.environ.get(\"VERTEXAI_PROJECT_ID\"), location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b78a16-daec-4a9d-9e7d-49167f8d3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = os.environ.get(\"GCLOUD_BUCKET_NAME\")  # Should have the form \"cloud-ai-platform-<YOUR_BUCKET>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28ac58-4efa-43ed-a7a9-2a3d317e5537",
   "metadata": {},
   "source": [
    "## Create batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ea97c73-494b-4c11-be0f-552b7ff316e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = create_batch(\n",
    "    dataset,\n",
    "    api=\"google\",\n",
    "    model=\"gemini-1.5-pro-002\",\n",
    "    fewshot_messages=[],\n",
    "    system_prompt=gemini_multiple_choice_0shot_sysprompt,\n",
    "    prompt_choices=\"from_text\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0,\n",
    "    seed=0,\n",
    "    stop_sequences=[\"I hope it is correct.\"],\n",
    "    # just to remove irrelevant params\n",
    "    logprobs=None,\n",
    "    top_p=None,\n",
    ")\n",
    "write_jsonl(\n",
    "    batch,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_from-text.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89f2cd06-1d4a-4e50-9f1e-1075d6a66f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': {'contents': [{'role': 'user',\n",
       "    'parts': [{'text': 'Problem:\\nIf $64$ is divided into three parts proportional to $2$, $4$, and $6$, the smallest part is:\\n$\\\\textbf{(A)}\\\\ 5\\\\frac{1}{3}\\\\qquad\\\\textbf{(B)}\\\\ 11\\\\qquad\\\\textbf{(C)}\\\\ 10\\\\frac{2}{3}\\\\qquad\\\\textbf{(D)}\\\\ 5\\\\qquad\\\\textbf{(E)}\\\\ \\\\text{None of these answers}$'}]},\n",
       "   {'role': 'model', 'parts': [{'text': 'Solution:'}]}],\n",
       "  'generation_config': {'temperature': 0,\n",
       "   'candidate_count': 1,\n",
       "   'max_output_tokens': 2048,\n",
       "   'stop_sequences': ['I hope it is correct.'],\n",
       "   'seed': 0},\n",
       "  'system_instruction': {'parts': [{'text': 'You are a math expert. Solve the following math Problem, thinking step by step. End the Solution with the final answer in the form \"Final Answer: The final answer is ?. I hope it is correct.\", where ? is replaced by one of the letters A, B, C, D or E.'}]}},\n",
       " 'model': 'gemini-1.5-pro-002'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be5154de-03d6-4650-8d11-037bda12245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': {'contents': [{'role': 'user',\n",
       "    'parts': [{'text': 'Problem:\\nIf $64$ is divided into three parts proportional to $2$, $4$, and $6$, the smallest part is:\\nA. $5\\\\frac{1}{3}$\\nB. $11$\\nC. $10\\\\frac{2}{3}$\\nD. $5$\\nE. $\\\\text{None of these answers}$'}]},\n",
       "   {'role': 'model', 'parts': [{'text': 'Solution:'}]}],\n",
       "  'generation_config': {'temperature': 0,\n",
       "   'candidate_count': 1,\n",
       "   'max_output_tokens': 2048,\n",
       "   'stop_sequences': ['I hope it is correct.'],\n",
       "   'seed': 0},\n",
       "  'system_instruction': {'parts': [{'text': 'You are a math expert. Solve the following math Problem, thinking step by step. End the Solution with the final answer in the form \"Final Answer: The final answer is ?. I hope it is correct.\", where ? is replaced by one of the letters A, B, C, D or E.'}]}},\n",
       " 'model': 'gemini-1.5-pro-002'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = create_batch(\n",
    "    dataset,\n",
    "    api=\"google\",\n",
    "    model=\"gemini-1.5-pro-002\",\n",
    "    fewshot_messages=[],\n",
    "    system_prompt=gemini_multiple_choice_0shot_sysprompt,\n",
    "    prompt_choices=\"newline_dot\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0,\n",
    "    seed=0,\n",
    "    stop_sequences=[\"I hope it is correct.\"],\n",
    "    # just to remove irrelevant params\n",
    "    logprobs=None,\n",
    "    top_p=None,\n",
    ")\n",
    "write_jsonl(\n",
    "    batch,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_newline-dot.jsonl\",\n",
    ")\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a60eb885-e139-4197-9bf4-dde1f136c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': {'contents': [{'role': 'user',\n",
       "    'parts': [{'text': 'Problem:\\nIf $64$ is divided into three parts proportional to $2$, $4$, and $6$, the smallest part is:\\n(A) $5\\\\frac{1}{3}$\\n(B) $11$\\n(C) $10\\\\frac{2}{3}$\\n(D) $5$\\n(E) $\\\\text{None of these answers}$'}]},\n",
       "   {'role': 'model', 'parts': [{'text': 'Solution:'}]}],\n",
       "  'generation_config': {'temperature': 0,\n",
       "   'candidate_count': 1,\n",
       "   'max_output_tokens': 2048,\n",
       "   'stop_sequences': ['I hope it is correct.'],\n",
       "   'seed': 0},\n",
       "  'system_instruction': {'parts': [{'text': 'You are a math expert. Solve the following math Problem, thinking step by step. End the Solution with the final answer in the form \"Final Answer: The final answer is ?. I hope it is correct.\", where ? is replaced by one of the letters A, B, C, D or E.'}]}},\n",
       " 'model': 'gemini-1.5-pro-002'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = create_batch(\n",
    "    dataset,\n",
    "    api=\"google\",\n",
    "    model=\"gemini-1.5-pro-002\",\n",
    "    fewshot_messages=[],\n",
    "    system_prompt=gemini_multiple_choice_0shot_sysprompt,\n",
    "    prompt_choices=\"newline_paren\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0,\n",
    "    seed=0,\n",
    "    stop_sequences=[\"I hope it is correct.\"],\n",
    "    # just to remove irrelevant params\n",
    "    logprobs=None,\n",
    "    top_p=None,\n",
    ")\n",
    "write_jsonl(\n",
    "    batch,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren.jsonl\",\n",
    ")\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "958fda23-2d22-4704-8e80-e47df08842c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': {'contents': [{'role': 'user',\n",
       "    'parts': [{'text': 'Problem:\\nIf $64$ is divided into three parts proportional to $2$, $4$, and $6$, the smallest part is:'}]},\n",
       "   {'role': 'model', 'parts': [{'text': 'Solution:'}]}],\n",
       "  'generation_config': {'temperature': 0,\n",
       "   'candidate_count': 1,\n",
       "   'max_output_tokens': 2048,\n",
       "   'stop_sequences': ['I hope it is correct.'],\n",
       "   'seed': 0},\n",
       "  'system_instruction': {'parts': [{'text': 'You are a math expert. Solve the following math Problem, thinking step by step. End the Solution with the final answer in the form \"Final Answer: The final answer is ?. I hope it is correct.\", where ? is replaced by one of the letters A, B, C, D or E.'}]}},\n",
       " 'model': 'gemini-1.5-pro-002'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = create_batch(\n",
    "    dataset,\n",
    "    api=\"google\",\n",
    "    model=\"gemini-1.5-pro-002\",\n",
    "    fewshot_messages=[],\n",
    "    system_prompt=gemini_multiple_choice_0shot_sysprompt,\n",
    "    prompt_choices=None,\n",
    "    max_tokens=2048,\n",
    "    temperature=0,\n",
    "    seed=0,\n",
    "    stop_sequences=[\"I hope it is correct.\"],\n",
    "    # just to remove irrelevant params\n",
    "    logprobs=None,\n",
    "    top_p=None,\n",
    ")\n",
    "write_jsonl(\n",
    "    batch,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_none.jsonl\",\n",
    ")\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d29b20-3d43-4c76-af1e-66d60e975b8e",
   "metadata": {},
   "source": [
    "## Upload to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32dff5-13e6-4720-b000-5f63c0314ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_blob(\n",
    "    BUCKET_NAME,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_from-text.jsonl\",\n",
    "    \"prompt_data/mcq/gemini-1.5-pro-002/batch_choices_from-text.jsonl\",\n",
    ")\n",
    "upload_blob(\n",
    "    BUCKET_NAME,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_newline-dot.jsonl\",\n",
    "    \"prompt_data/mcq/gemini-1.5-pro-002/batch_choices_newline-dot.jsonl\",\n",
    ")\n",
    "upload_blob(\n",
    "    BUCKET_NAME,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren.jsonl\",\n",
    "    \"prompt_data/mcq/gemini-1.5-pro-002/batch_choices_newline-paren.jsonl\",\n",
    ")\n",
    "upload_blob(\n",
    "    BUCKET_NAME,\n",
    "    BASEDIR / \"inputs/mcq/gemini-1.5-pro-002/batch_choices_none.jsonl\",\n",
    "    \"prompt_data/mcq/gemini-1.5-pro-002/batch_choices_none.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ac3e5-3ff5-431f-9134-802e3904a034",
   "metadata": {},
   "source": [
    "## Run batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a08f20-5e86-4b9e-979a-df5b4adabac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-pro-002\",\n",
    "    input_dataset=f\"gs://{BUCKET_NAME}/prompt_data/mcq/gemini-1.5-pro-002/batch_choices_from-text.jsonl\",\n",
    "    output_uri_prefix=f\"gs://{BUCKET_NAME}/outputs/mcq/gemini-1.5-pro-002/batch_choices_from-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67376f6d-6fbb-44d9-a2bf-52d1b24ccb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-pro-002\",\n",
    "    input_dataset=f\"gs://{BUCKET_NAME}/prompt_data/mcq/gemini-1.5-pro-002/batch_choices_newline-dot.jsonl\",\n",
    "    output_uri_prefix=f\"gs://{BUCKET_NAME}/outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-dot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a26407-86ea-4827-9de0-a3a9897b1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-pro-002\",\n",
    "    input_dataset=f\"gs://{BUCKET_NAME}/prompt_data/mcq/gemini-1.5-pro-002/batch_choices_newline-paren.jsonl\",\n",
    "    output_uri_prefix=f\"gs://{BUCKET_NAME}/outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e214b-53e6-483d-b5d0-c518abd1e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-pro-002\",\n",
    "    input_dataset=f\"gs://{BUCKET_NAME}/prompt_data/mcq/gemini-1.5-pro-002/batch_choices_none.jsonl\",\n",
    "    output_uri_prefix=f\"gs://{BUCKET_NAME}/outputs/mcq/gemini-1.5-pro-002/batch_choices_none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d6995-523c-4c40-9d07-74a1da0f1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_from-text/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_from-text.jsonl\",\n",
    ")\n",
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-dot/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_newline-dot.jsonl\",\n",
    ")\n",
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_newline-paren/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_newline-paren.jsonl\",\n",
    ")\n",
    "download_blob(\n",
    "    BUCKET_NAME,\n",
    "    \"outputs/mcq/gemini-1.5-pro-002/batch_choices_none/prediction-model-<TIMESTAMP>/predictions.jsonl\",\n",
    "    BASEDIR / \"outputs/mcq/gemini-1.5-pro-002/outputs_none.jsonl\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
